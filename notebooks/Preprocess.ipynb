{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Reading in TrigramVecs...\n",
      "Number of possible 3-grams: 9048\n",
      "Dimension of TrigramVecs: 100\n",
      "\n",
      "---> Reading in strains...\n",
      "Strains from 6 years were read.\n",
      "Shape: 6x577x566\n",
      "Example strain:\n",
      "MKTIIALSYILCLVFAQKLPGNDNSTATLCLGHHAVPNGTIVKTITNDQIEVTNATELVQSSSTGEICDSPHQILDGENCTLIDALLGDPQCDGFQNKKWDLFVERSKAYSNCYPYDVPDYASLRSLVASSGTLEFNNESFNWTGVTQNGTSSACIRRSNSSFFSRLNWLTHLNFKYPALNVTMPNNEQFDKLYIWGVHHPGTDKDQIFLYAQSSGRITVSTKRSQQAVIPNIGSRPRIRNIPSRISIYWTIVKPGDILLINSTGNLIAPRGYFKIRSGKSSIMRSDAPIGKCNSECITPNGSIPNDKPFQNVNRITYGACPRYVKQSTLKLATGMRNVPEKQTRGIFGAIAGFIENGWEGMVDGWYGFRHQNSEGRGQAADLKSTQAAIDQINGKLNRLIGKTNEKFHQIEKEFSEVEGRIQDLEKYVEDTKIDLWSYNAELLVALENQHTIDLTDSEMNKLFEKTKKQLRENAEDMGNGCFKIYHKCDNACIESIRNGTYNHDVYRDEALNNRFQIKGVELKSGYKDWILWISFAISCFLLCVALLGFIMWACQKGNIRCNICI\n",
      "\n",
      "---> Constructing training data...\n",
      "Each of 100 year strains were split into 564 trigrams.\n",
      "Shape: 6x100x564\n",
      "\n",
      "Index conversion performed.\n",
      "Shape: 6x100x564\n",
      "\n",
      "Index concatenation performed.\n",
      "Shape: 6x56400\n",
      "\n",
      "TrigramVec conversion performed.\n",
      "Shape: 6:56400:100\n",
      "\n",
      "---> Compering to original code...\n",
      "ProtVec conversion performed.\n",
      "Shape: 6:56400:100\n"
     ]
    }
   ],
   "source": [
    "from src.data import make_dataset\n",
    "from src.features import build_features\n",
    "from src.features import original\n",
    "\n",
    "data_files = ['2011.csv', '2012.csv', '2013.csv', '2014.csv', '2015.csv', '2016.csv']\n",
    "\n",
    "print('---> Reading in TrigramVecs...')\n",
    "trigram_to_idx, trigram_vecs_data = make_dataset.read_trigram_vecs()\n",
    "print(f'Number of possible 3-grams: {len(trigram_to_idx)}')\n",
    "print(f'Dimension of TrigramVecs: {len(trigram_vecs_data[0])}')\n",
    "\n",
    "print('\\n---> Reading in strains...')\n",
    "strains_by_year = make_dataset.read_strains_from(data_files)\n",
    "print(f'Strains from {len(data_files)} years were read.')\n",
    "print(f'Shape: {len(strains_by_year)}x{len(strains_by_year[0])}x{len(strains_by_year[0][0])}')\n",
    "print(f'Example strain:\\n{strains_by_year[0][0]}')\n",
    "\n",
    "print('\\n---> Constructing training data...')\n",
    "num_of_samples = 100\n",
    "\n",
    "strains_by_year = build_features.sample_strains(strains_by_year, num_of_samples)\n",
    "\n",
    "trigrams_by_year = build_features.split_to_trigrams(strains_by_year)\n",
    "print(f'Each of {len(trigrams_by_year[0])} year strains were split into {len(trigrams_by_year[0][0])} trigrams.')\n",
    "print(f'Shape: {len(trigrams_by_year)}x{len(trigrams_by_year[0])}x{len(trigrams_by_year[0][0])}')\n",
    "\n",
    "trigram_idxs_by_year = build_features.trigrams_to_indexes(trigrams_by_year, trigram_to_idx)\n",
    "print('\\nIndex conversion performed.')\n",
    "print(f'Shape: {len(trigram_idxs_by_year)}x{len(trigram_idxs_by_year[0])}x{len(trigram_idxs_by_year[0][0])}')\n",
    "\n",
    "concated_trigrams_by_year = build_features.concat_trigrams(trigram_idxs_by_year)\n",
    "print('\\nIndex concatenation performed.')\n",
    "print(f'Shape: {len(concated_trigrams_by_year)}x{len(concated_trigrams_by_year[0])}')\n",
    "\n",
    "trigram_vecs = build_features.indexes_to_trigram_vecs(concated_trigrams_by_year, trigram_vecs_data)\n",
    "print('\\nTrigramVec conversion performed.')\n",
    "print(f'Shape: {len(training_vecs)}:{len(training_vecs[0])}:{len(training_vecs[0][0])}')\n",
    "\n",
    "print('\\n---> Compering to original code...')\n",
    "num_of_samples = 100\n",
    "training_trigrams = original.construct_training_data(strains_by_year, num_of_samples)\n",
    "training_indexes = original.convert_to_indexes(training_trigrams, trigram_to_idx)\n",
    "training_vecs = original.convert_to_prot_vecs(training_indexes, trigram_vecs_data)\n",
    "print('ProtVec conversion performed.')\n",
    "print(f'Shape: {len(training_vecs)}:{len(training_vecs[0])}:{len(training_vecs[0][0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
