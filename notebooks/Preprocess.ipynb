{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Reading in TrigramVecs...\n",
      "Number of possible 3-grams: 9048\n",
      "Dimension of TrigramVecs: 100\n",
      "\n",
      "---> Reading in strains...\n",
      "Strains from 6 years were read.\n",
      "Example strain:\n",
      "MKTIIALSYILCLVFAQKLPGNDNSTATLCLGHHAVPNGTIVKTITNDQIEVTNATELVQSSSTGEICDSPHQILDGENCTLIDALLGDPQCDGFQNKKWDLFVERSKAYSNCYPYDVPDYASLRSLVASSGTLEFNNESFNWTGVTQNGTSSACIRRSNSSFFSRLNWLTHLNFKYPALNVTMPNNEQFDKLYIWGVHHPGTDKDQIFLYAQSSGRITVSTKRSQQAVIPNIGSRPRIRNIPSRISIYWTIVKPGDILLINSTGNLIAPRGYFKIRSGKSSIMRSDAPIGKCNSECITPNGSIPNDKPFQNVNRITYGACPRYVKQSTLKLATGMRNVPEKQTRGIFGAIAGFIENGWEGMVDGWYGFRHQNSEGRGQAADLKSTQAAIDQINGKLNRLIGKTNEKFHQIEKEFSEVEGRIQDLEKYVEDTKIDLWSYNAELLVALENQHTIDLTDSEMNKLFEKTKKQLRENAEDMGNGCFKIYHKCDNACIESIRNGTYNHDVYRDEALNNRFQIKGVELKSGYKDWILWISFAISCFLLCVALLGFIMWACQKGNIRCNICI\n",
      "\n",
      "---> Constructing training data...\n",
      "100 amino acid sequences sampled from each year to create 56400 training examples.\n",
      "Examples: [['MKT', 'MKT', 'MKT', 'MKT', 'MKT', 'MKT'], ['KTI', 'KTI', 'KTI', 'KTI', 'KTI', 'KTI']]\n",
      "Shape: 56400x6\n",
      "\n",
      "Index conversion performed.\n",
      "Examples: [[4233 1356 1883 ... 6525 6496 5856]\n",
      " [4233 1356 1883 ... 6525 6496 5856]]\n",
      "Shape: 6x56400\n",
      "\n",
      "ProtVec conversion performed.\n",
      "Shape: 6:56400:100\n"
     ]
    }
   ],
   "source": [
    "from src.data import make_dataset\n",
    "from src.features import build_features\n",
    "from src.features import original\n",
    "from src.utils import utils\n",
    "\n",
    "data_files = ['2011.csv', '2012.csv', '2013.csv', '2014.csv', '2015.csv', '2016.csv']\n",
    "\n",
    "print('---> Reading in TrigramVecs...')\n",
    "trigram_to_idx, trigram_vecs_data = make_dataset.read_trigram_vecs()\n",
    "print(f'Number of possible 3-grams: {len(trigram_to_idx)}')\n",
    "print(f'Dimension of TrigramVecs: {len(trigram_vecs_data[0])}')\n",
    "\n",
    "print('\\n---> Reading in strains...')\n",
    "strains_by_year = make_dataset.read_strains_from(data_files)\n",
    "print(f'Strains from {len(data_files)} years were read.')\n",
    "print(f'Example strain:\\n{strains_by_year[0][0]}')\n",
    "\n",
    "# print('\\n---> Constructing training data...')\n",
    "# num_of_samples = 2\n",
    "\n",
    "# strains_by_year = build_features.sample_strains(raw_amino_sequences, num_of_samples)\n",
    "# print(f'Picked {len(strains_by_year[0])} strains by year')\n",
    "\n",
    "# trigrams_by_year = build_features.split_to_trigrams(strains_by_year)\n",
    "# print(f'Each of {len(trigrams_by_year[0])} year strains were split into {len(trigrams_by_year[0][0])} trigrams.')\n",
    "\n",
    "# trigrams_series = build_features.to_time_series(trigrams_by_year)\n",
    "# # print(f'{len(trigrams_series[0])/564} strains sampled from each year to create {len(trigrams_series)} training examples.')\n",
    "# # print(f'Example: {trigrams_series}, length: {len(trigrams_series)}')\n",
    "\n",
    "# training_indexes = build_features.trigrams_to_indexes(trigrams_series, trigram_to_idx)\n",
    "# print('\\nIndex conversion performed.')\n",
    "# print(f'Example: {training_indexes[:2]}')\n",
    "# trigram_vecs = build_features.indexes_to_trigram_vecs(training_indexes, trigram_vecs_data)\n",
    "# print('\\nTrigramVec conversion performed.')\n",
    "# print(f'It\\'s {len(trigram_vecs)} trigrams in strains of each of {len(trigram_vecs[0])} years where' +\n",
    "#     f' each Trigram is encoded by {len(trigram_vecs[0][0])} numbers')\n",
    "\n",
    "\n",
    "print('\\n---> Constructing training data...')\n",
    "num_of_samples = 100\n",
    "training_trigrams = original.construct_training_data(strains_by_year, num_of_samples)\n",
    "print('%d amino acid sequences sampled from each year to create %d training examples.' % (num_of_samples, len(training_trigrams)))\n",
    "print('Examples: {}'.format(training_trigrams[:2]))\n",
    "print(f'Shape: {len(training_trigrams)}x{len(training_trigrams[0])}')\n",
    "\n",
    "training_indexes = original.convert_to_indexes(training_trigrams, trigram_to_idx)\n",
    "print('\\nIndex conversion performed.')\n",
    "print('Examples: {}'.format(training_indexes[:2]))\n",
    "print(f'Shape: {len(training_indexes)}x{len(training_indexes[0])}')\n",
    "\n",
    "training_vecs = original.convert_to_prot_vecs(training_indexes, trigram_vecs_data)\n",
    "print('\\nProtVec conversion performed.')\n",
    "print(f'Shape: {len(training_vecs)}:{len(training_vecs[0])}:{len(training_vecs[0][0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
